{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef08f3a2-02a0-4b27-b06e-754542556363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df3fb27-e59c-4f4e-a004-b8b2a00a61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'C:/Users/Aziz/Desktop/Alzheimer_s Dataset/Alzheimer_s Dataset/train'  \n",
    "test_dir = 'C:/Users/Aziz/Desktop/Alzheimer_s Dataset/Alzheimer_s Dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d2b01e-8b61-423e-acde-d48fa7902d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (128, 128)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2200f26-3740-4f0e-9fe4-f28d8cc867c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "478e37e7-c0bb-4e96-acb7-127ea5ede3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4098 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed779501-7194-40b6-84e5-1493219c3e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 254 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "379c46f8-cf2a-4837-ae49-8c7993c319f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aziz\\Downloads\\Programs\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build the CNN Feature Extractor\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf5ff0e-b318-409e-858b-a9777ea9ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68eb01e5-62e1-4e02-8255-a19a92ef53f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aziz\\Downloads\\Programs\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Extract Features Using CNN\n",
    "features_train = cnn_model.predict(train_generator)\n",
    "features_test = cnn_model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67310340-3f03-4fcb-9d24-4c0291b16d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the CNN model\n",
    "cnn_model.save('cnn_feature_extractor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f752e71-4c58-41e5-9193-eec788f45e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build and Train the ANN Model\n",
    "ann_model = Sequential([\n",
    "    Input(shape=(features_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(4, activation='softmax')  # Adjust the number of classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cb99573-9255-42d2-ad7c-37b53728e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79c79172-f5ad-4f7f-9250-43063f0ba71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "train_labels = np.array(train_generator.labels)\n",
    "test_labels = np.array(test_generator.labels)\n",
    "train_labels_one_hot = tf.keras.utils.to_categorical(train_labels, num_classes=4)\n",
    "test_labels_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4315fb28-b3b7-4195-9e81-c56b88e7d870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4718 - loss: 1.1504 - val_accuracy: 0.5039 - val_loss: 1.0266\n",
      "Epoch 2/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5032 - loss: 1.0288 - val_accuracy: 0.5039 - val_loss: 1.0274\n",
      "Epoch 3/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5101 - loss: 1.0321 - val_accuracy: 0.5039 - val_loss: 1.0274\n",
      "Epoch 4/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5014 - loss: 1.0466 - val_accuracy: 0.5039 - val_loss: 1.0276\n",
      "Epoch 5/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5134 - loss: 1.0277 - val_accuracy: 0.5039 - val_loss: 1.0280\n",
      "Epoch 6/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5012 - loss: 1.0344 - val_accuracy: 0.5039 - val_loss: 1.0279\n",
      "Epoch 7/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5003 - loss: 1.0481 - val_accuracy: 0.5039 - val_loss: 1.0275\n",
      "Epoch 8/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4994 - loss: 1.0363 - val_accuracy: 0.5039 - val_loss: 1.0279\n",
      "Epoch 9/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5049 - loss: 1.0358 - val_accuracy: 0.5039 - val_loss: 1.0261\n",
      "Epoch 10/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5026 - loss: 1.0203 - val_accuracy: 0.5039 - val_loss: 1.0372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f2a8d83bf0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the ANN model\n",
    "ann_model.fit(features_train, train_labels_one_hot, validation_data=(features_test, test_labels_one_hot), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc9f6ca6-fe67-4206-8cd9-fce55c15b743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Test Accuracy: 50.39%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "predictions = np.argmax(ann_model.predict(features_test), axis=1)\n",
    "test_accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2efeef5a-cb64-40ac-862e-79cc5fe68e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the ANN model\n",
    "ann_model.save('ann_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ee73e58-e383-42d2-870e-0170342440ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "WARNING:tensorflow:5 out of the last 19 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F2B2F3AB60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 19 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F2B2F3AB60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "The image is classified as: NonDemented\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Classify New Images\n",
    "def classify_image(img_path):\n",
    "    # Load the saved CNN and ANN models\n",
    "    cnn_model = tf.keras.models.load_model('cnn_feature_extractor.h5')\n",
    "    ann_model = tf.keras.models.load_model('ann_model.h5')\n",
    "\n",
    "    # Load and preprocess the new image\n",
    "    img = image.load_img(img_path, target_size=img_size)  # Resize to match CNN input\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Normalize\n",
    "\n",
    "    # Extract features using the CNN model\n",
    "    features = cnn_model.predict(img_array)\n",
    "    features = features.reshape(1, -1)  # Flatten for ANN\n",
    "\n",
    "    # Classify the features with the ANN model\n",
    "    prediction = ann_model.predict(features)\n",
    "    predicted_class = np.argmax(prediction, axis=1)  # Get the class with the highest probability\n",
    "\n",
    "    # Interpret the prediction\n",
    "    class_labels = {0: 'MildDemented', 1: 'ModerateDemented', 2: 'NonDemented', 3: 'VeryMildDemented'}\n",
    "    result = class_labels[predicted_class[0]]\n",
    "    return result\n",
    "\n",
    "# Test the function with a new image\n",
    "img_path = r'C:/Users/Aziz/Desktop/Alzheimer_s Dataset/Alzheimer_s Dataset/test/NonDemented/27 (89).jpg'\n",
    "result = classify_image(img_path)\n",
    "print(f\"The image is classified as: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8361c5-2a25-49bb-9222-6f9c0ec25937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
